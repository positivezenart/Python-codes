{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMts83M6JSCFfFe3CTTSlW1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/positivezenart/Python-codes/blob/main/pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EobPfaurWHbo"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "zF2OYMAIWnF7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "8ypr3Sh8Wo6J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "8fYkiVwuWrIS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "V8x7G26eWtQy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "sc =SparkContext()"
      ],
      "metadata": {
        "id": "bGIkgdfcWvMB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing libraries"
      ],
      "metadata": {
        "id": "mElUkefsXcit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import expr,concat,col\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import concat, col, lit\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "from pyspark.sql.functions import col,struct,when"
      ],
      "metadata": {
        "id": "K2WCZNJvWyZf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications running on PySpark are 100x faster than\n",
        "\n",
        "traditional systems.\n",
        "You will get great benefits using PySpark for data ingestion pipelines.\n",
        "Using PySpark we can process data from Hadoop HDFS, AWS S3, and many file systems.\n",
        "PySpark also is used to process real-time data using Streaming and Kafka."
      ],
      "metadata": {
        "id": "zeZCgCqjYPYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spark Session:**\n",
        "SparkSession was introduced in version 2.0, It is an entry point to underlying PySpark functionality in order to programmatically create PySpark RDD, DataFrame.\n",
        "https://sparkbyexamples.com/pyspark/pyspark-what-is-sparksession/"
      ],
      "metadata": {
        "id": "UvYnLjqdZzvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (SparkSession.builder\n",
        "                      .appName('SparkByExamples.com') \n",
        "                      .getOrCreate())\n",
        "print(spark) #create a new session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByqUzSdRZ92g",
        "outputId": "8210000d-a460-4c22-b38e-04083e822153"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f6e8f3bea60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark2 = (SparkSession.newSession)\n",
        "print(spark2) #creating new session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oKnjgwkbZ-c",
        "outputId": "d368bff8-95f3-43cb-d22a-b3a89fc9bee8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function SparkSession.newSession at 0x7f6e8b567dc0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark3 = (SparkSession.builder.getOrCreate())\n",
        "print(spark3) #accessing the existing session"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-RGCSU-bmZU",
        "outputId": "79da3add-c438-44b8-ae4a-2d2118dde04d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<pyspark.sql.session.SparkSession object at 0x7f6e8f3bea60>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pyspark Dataframe"
      ],
      "metadata": {
        "id": "rLJyJYfPcCqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an empty RDD"
      ],
      "metadata": {
        "id": "WWTS89igcrl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "empty_rdd = spark.sparkContext.emptyRDD()\n",
        "print(empty_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5xSuOhXcHjb",
        "outputId": "5bb7c798-961e-4684-d4ea-b0c1ebb6016d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmptyRDD[0] at emptyRDD at NativeMethodAccessorImpl.java:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a schema\n",
        "schema = StructType([\n",
        "  StructField('firstname', StringType(), True),\n",
        "  StructField('middlename', StringType(), True),\n",
        "  StructField('lastname', StringType(), True)\n",
        "  ])\n"
      ],
      "metadata": {
        "id": "x6AcE3Vnc7pp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame(empty_rdd,schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BLqzD7YdReB",
        "outputId": "89fb5932-5b0e-4dee-9ef5-62489620e607"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vS_oVkydddC",
        "outputId": "bcf7e067-5563-45bd-b4b2-a55e17cd464c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easy way to create a empty dataframe"
      ],
      "metadata": {
        "id": "SXmVVwIsdmxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.createDataFrame([],schema)\n",
        "df1.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7POS-TlodqL6",
        "outputId": "0d3f2354-693c-425f-b39b-15141746e162"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+\n",
            "|firstname|middlename|lastname|\n",
            "+---------+----------+--------+\n",
            "+---------+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert spark df to pandas"
      ],
      "metadata": {
        "id": "ZrclYu6afVTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",60000),\n",
        "        (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",70000),\n",
        "        (\"Robert\",\"\",\"Williams\",\"42114\",\"\",400000),\n",
        "        (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",500000),\n",
        "        (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",0)]\n",
        "#columns\n",
        "columns = [\"first_name\",\"middle_name\",\"last_name\",\"dob\",\"gender\",\"salary\"]\n",
        "df3 = spark3.createDataFrame(data = data,schema= columns)"
      ],
      "metadata": {
        "id": "vWqLfPOHfYHf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.printSchema()\n",
        "df3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU5bsMjdgeTC",
        "outputId": "c263908a-0309-4315-bb27-1336ebc34744"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- middle_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "|first_name|middle_name|last_name|  dob|gender|salary|\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "|     James|           |    Smith|36636|     M| 60000|\n",
            "|   Michael|       Rose|         |40288|     M| 70000|\n",
            "|    Robert|           | Williams|42114|      |400000|\n",
            "|     Maria|       Anne|    Jones|39192|     F|500000|\n",
            "|       Jen|       Mary|    Brown|     |     F|     0|\n",
            "+----------+-----------+---------+-----+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.show(2,vertical=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3tlfBvGg7jA",
        "outputId": "aa9afc03-fa0d-4b3a-9c3d-ba61d4846c21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0--------------\n",
            " first_name  | James   \n",
            " middle_name |         \n",
            " last_name   | Smith   \n",
            " dob         | 36636   \n",
            " gender      | M       \n",
            " salary      | 60000   \n",
            "-RECORD 1--------------\n",
            " first_name  | Michael \n",
            " middle_name | Rose    \n",
            " last_name   |         \n",
            " dob         | 40288   \n",
            " gender      | M       \n",
            " salary      | 70000   \n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df3.toPandas()\n",
        "print(df4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zuMGRUoglni",
        "outputId": "eba058c5-9670-49aa-aa25-1b1e57354fc2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  first_name middle_name last_name    dob gender  salary\n",
            "0      James                 Smith  36636      M   60000\n",
            "1    Michael        Rose            40288      M   70000\n",
            "2     Robert              Williams  42114         400000\n",
            "3      Maria        Anne     Jones  39192      F  500000\n",
            "4        Jen        Mary     Brown             F       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark StructType & StructField** classes are used to programmatically specify the schema to the DataFrame and create complex columns like nested struct, array, and map columns. StructType is a collection of StructField’s that defines column name, column data type, boolean to specify if the field can be nullable or not and metadata."
      ],
      "metadata": {
        "id": "6VPnm7ijhULb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new spark session\n",
        "spark_struct = SparkSession.builder.appName(\"Struct_type\").getOrCreate()\n",
        "#columns data\n",
        "structureData = [\n",
        "    ((\"James\",\"\",\"Smith\"),36636,\"M\",3100),\n",
        "    ((\"Michael\",\"Rose\",\"\"),40288,\"M\",4300),\n",
        "    ((\"Robert\",\"\",\"Williams\"),42114,\"M\",1400),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),39192,\"F\",5500),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),0,\"F\",-1)\n",
        "  ]\n",
        "#schema file\n",
        "schema = StructType([ \n",
        "    StructField(\"name\",StructType([\n",
        "    StructField(\"firstname\",StringType(),True), \\\n",
        "    StructField(\"middlename\",StringType(),True), \\\n",
        "    StructField(\"lastname\",StringType(),True)])), \\\n",
        "    StructField(\"id\", IntegerType(), True), \\\n",
        "    StructField(\"gender\", StringType(), True), \\\n",
        "    StructField(\"salary\", IntegerType(), True) \\\n",
        "  ])\n",
        "#create Data frame\n",
        "df_struct = spark_struct.createDataFrame(structureData,schema)\n",
        "df_struct.show()\n",
        "df_struct.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTGEHzW_hU_d",
        "outputId": "d99309fa-d07d-4a39-e479-043e18cda160"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+------+\n",
            "|                name|   id|gender|salary|\n",
            "+--------------------+-----+------+------+\n",
            "|    [James, , Smith]|36636|     M|  3100|\n",
            "|   [Michael, Rose, ]|40288|     M|  4300|\n",
            "|[Robert, , Williams]|42114|     M|  1400|\n",
            "|[Maria, Anne, Jones]|39192|     F|  5500|\n",
            "|  [Jen, Mary, Brown]|    0|     F|    -1|\n",
            "+--------------------+-----+------+------+\n",
            "\n",
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- id: integer (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updatedDF = df_struct.withColumn(\"Other_info\",\n",
        "                      struct(col(\"id\").alias(\"identifier\"),\n",
        "                             col(\"gender\").alias(\"gender\"),\n",
        "                             col(\"salary\").alias(\"salary\"),\n",
        "                             when(col(\"salary\").cast(IntegerType()) <2000,\"Low\")\n",
        "                             .when(col(\"salary\").cast(IntegerType())<4000,\"medium\")\n",
        "                             .otherwise(col(\"salary\").alias(\"Salary_grade\"))))"
      ],
      "metadata": {
        "id": "LeRm4GszlZ9p"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updatedDF.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YGPiq5vmAdk",
        "outputId": "cd27029f-52ae-40f2-edb4-20ea9e57042a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+------+------+------------------------+\n",
            "|name                |id   |gender|salary|Other_info              |\n",
            "+--------------------+-----+------+------+------------------------+\n",
            "|[James, , Smith]    |36636|M     |3100  |[36636, M, 3100, medium]|\n",
            "|[Michael, Rose, ]   |40288|M     |4300  |[40288, M, 4300, 4300]  |\n",
            "|[Robert, , Williams]|42114|M     |1400  |[42114, M, 1400, Low]   |\n",
            "|[Maria, Anne, Jones]|39192|F     |5500  |[39192, F, 5500, 5500]  |\n",
            "|[Jen, Mary, Brown]  |0    |F     |-1    |[0, F, -1, Low]         |\n",
            "+--------------------+-----+------+------+------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}